# src/chat_bot.py
import yaml
import json
import pandas as pd
import os
from typing import Optional, List, Tuple, Dict, Any
from datetime import datetime

# Sá»­ dá»¥ng import tÆ°Æ¡ng Ä‘á»‘i Ä‘á»ƒ code sáº¡ch hÆ¡n
from .data_utils.data_loader import load_all_sheets_from_excel
from .core.retriever import AnimeRetriever
from .core.model_handler import LLMHandler
from .core.prompt_manager import create_rag_prompt, create_direct_answer_prompt, create_general_prompt

class Chatbot:
    def __init__(self, config_path: str, model_config_path: str):
        print("\n" + "="*50)
        print("ðŸ¤– Báº®T Äáº¦U KHá»žI Táº O ANIBOT ðŸ¤–")
        print("="*50)
        
        with open(config_path, 'r', encoding='utf-8') as f: self.config = yaml.safe_load(f)
        with open(model_config_path, 'r', encoding='utf-8') as f: self.model_config = json.load(f)

        self._load_data_sources()
        
        self.retriever = AnimeRetriever(self.config)
        self.llm_handler = LLMHandler(
            model_path=self.config['models']['llm_local_path'], 
            model_config=self.model_config['llm_params']
        )
        print("\n" + "="*50)
        print("âœ¨ AniBot Ä‘Ã£ khá»Ÿi táº¡o thÃ nh cÃ´ng vÃ  sáºµn sÃ ng phá»¥c vá»¥! âœ¨")
        print("="*50 + "\n")

    def _load_data_sources(self):
        """Táº£i táº¥t cáº£ dá»¯ liá»‡u tá»« file Excel."""
        print("[*] Äang táº£i cÃ¡c nguá»“n dá»¯ liá»‡u tá»« Excel...")
        excel_path = self.config['data']['excel_path']
        self.all_data = load_all_sheets_from_excel(excel_path)
        
        # Thiáº¿t láº­p cÃ¡c DataFrame chÃ­nh
        self.anime_info_df = self.all_data.get(self.config['data']['knowledge_base_sheet'])
        if self.anime_info_df is not None:
            self.anime_info_df = self.anime_info_df.set_index('ID')
            print("    - ÄÃ£ táº£i vÃ  thiáº¿t láº­p Knowledge Base.")
        
        self.recommendations_df = self.all_data.get(self.config['data']['recommendations_sheet'])
        self.faq_df = self.all_data.get(self.config['data']['faq_sheet'])
        self.quick_answers_df = self.all_data.get(self.config['data']['quick_answers_sheet'])
        self.watch_order_df = self.all_data.get(self.config['data']['watch_order_sheet'])
        print("âœ… ÄÃ£ táº£i xong dá»¯ liá»‡u.")

    def answer(self, query: str, chat_history: List[Tuple[str, str]] = None) -> str:
        """
        Xá»­ lÃ½ cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng qua nhiá»u lá»›p logic Ä‘á»ƒ Ä‘Æ°a ra cÃ¢u tráº£ lá»i phÃ¹ há»£p nháº¥t.

        Args:
            query (str): CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng.
            chat_history (List[Tuple[str, str]]): Lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n.

        Returns:
            str: CÃ¢u tráº£ lá»i cá»§a bot.
        """
        if chat_history is None:
            chat_history = []
            
        print(f"\n[QUERY] NgÆ°á»i dÃ¹ng: '{query}' (Lá»‹ch sá»­: {len(chat_history)} lÆ°á»£t)")
        response = ""
        log_type = "UNKNOWN"

        # Lá»›p 1: CÃ¡c quy táº¯c cá»©ng vÃ  nhanh
        response, log_type = self._handle_hard_rules(query)
        if response:
            self._save_conversation(query, response, log_type)
            return response
            
        # Lá»›p 2: CÃ¡c quy táº¯c má»m dá»±a trÃªn template (cáº§n LLM diá»…n giáº£i)
        response, log_type = self._handle_soft_rules(query, chat_history)
        if response:
            self._save_conversation(query, response, log_type)
            return response

        # Lá»›p 3: RAG - Truy xuáº¥t vÃ  táº¡o sinh
        print("[LOG] KhÃ´ng khá»›p quy táº¯c, chuyá»ƒn sang RAG...")
        context = self._get_context_from_ids(self.retriever.search(query))
        if context:
            log_type = "RAG"
            prompt = create_rag_prompt(query, context, chat_history)
            response = self.llm_handler.generate(prompt)
            print(f"[LOG] Tráº£ lá»i tá»« RAG.")
        
        # Lá»›p 4: Fallback - DÃ¹ng kiáº¿n thá»©c chung cá»§a LLM
        else:
            log_type = "GENERAL_KNOWLEDGE"
            print("[LOG] KhÃ´ng tÃ¬m tháº¥y context, dÃ¹ng kiáº¿n thá»©c chung cá»§a LLM.")
            prompt = create_general_prompt(query, chat_history)
            response = self.llm_handler.generate(prompt)

        self._save_conversation(query, response, log_type)
        return response

    def _handle_hard_rules(self, query: str) -> Tuple[Optional[str], str]:
        """Xá»­ lÃ½ cÃ¡c cÃ¢u há»i cÃ³ cÃ¢u tráº£ lá»i cá»‘ Ä‘á»‹nh."""
        query_lower = query.lower().strip()
        
        # ChÃ o há»i
        greetings = ['hi', 'hello', 'chÃ o báº¡n', 'xin chÃ o']
        if query_lower in greetings:
            return "ChÃ o báº¡n, tÃ´i lÃ  AniBot. TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n vá» tháº¿ giá»›i anime?", "GREETING"
        
        # Giá»›i thiá»‡u báº£n thÃ¢n
        if "báº¡n lÃ  ai" in query_lower or "tÃªn báº¡n lÃ  gÃ¬" in query_lower:
            return "TÃ´i lÃ  AniBot, má»™t trá»£ lÃ½ AI Ä‘Æ°á»£c táº¡o ra Ä‘á»ƒ giÃºp báº¡n khÃ¡m phÃ¡ tháº¿ giá»›i anime.", "PERSONA"

        # FAQ
        faq_answer = self._find_answer_in_sheet(query, self.faq_df, 'Keywords', 'Solution')
        if faq_answer:
            print("[LOG] TÃ¬m tháº¥y trong FAQ.")
            return faq_answer, "FAQ"

        return None, ""
        
    def _handle_soft_rules(self, query: str, history: List[Tuple[str, str]]) -> Tuple[Optional[str], str]:
        """Xá»­ lÃ½ cÃ¡c cÃ¢u há»i dá»±a trÃªn template vÃ  cáº§n LLM diá»…n giáº£i."""
        # Thá»© tá»± xem
        if "thá»© tá»± xem" in query.lower() or "watch order" in query.lower():
            for _, row in self.watch_order_df.iterrows():
                if str(row['Series Name']).lower() in query.lower():
                    info = f"Thá»© tá»± xem cho {row['Series Name']} lÃ : {row['Watch Order']}. Ghi chÃº: {row['Note']}"
                    prompt = create_direct_answer_prompt(query, info, history)
                    return self.llm_handler.generate(prompt), "WATCH_ORDER"
        
        # Gá»£i Ã½ anime tÆ°Æ¡ng tá»±
        if "giá»‘ng" in query.lower() or "tÆ°Æ¡ng tá»±" in query.lower():
            for _, row in self.recommendations_df.iterrows():
                if str(row['User Likes']).lower() in query.lower():
                    info = f"Náº¿u báº¡n thÃ­ch {row['User Likes']}, báº¡n cÃ³ thá»ƒ sáº½ thÃ­ch {row['Recommend']} vÃ¬ {row['Reason']}."
                    prompt = create_direct_answer_prompt(query, info, history)
                    return self.llm_handler.generate(prompt), "RECOMMENDATION"
        
        return None, ""

    def _find_answer_in_sheet(self, query: str, df: Optional[pd.DataFrame], keyword_col: str, answer_col: str) -> Optional[str]:
        if df is None: return None
        for _, row in df.iterrows():
            if pd.isna(row[keyword_col]): continue
            keywords = [kw.strip().lower() for kw in str(row[keyword_col]).split(',')]
            if any(kw in query.lower() for kw in keywords if kw):
                return row[answer_col]
        return None

    def _get_context_from_ids(self, ids: List[int]) -> str:
        """Táº¡o chuá»—i context tá»« danh sÃ¡ch ID anime."""
        if not ids or self.anime_info_df is None: return ""
        
        context_parts = []
        valid_ids = [id_val for id_val in ids if id_val in self.anime_info_df.index]
        
        if not valid_ids: return ""
        
        for _, row in self.anime_info_df.loc[valid_ids].iterrows():
            context_parts.append(f"TÃªn: {row['Title']}\nMÃ´ táº£: {row['Short Description']}")
        
        return "\n---\n".join(context_parts)

    def _save_conversation(self, query: str, response: str, log_type: str):
        """LÆ°u láº¡i cuá»™c trÃ² chuyá»‡n vÃ o file log."""
        log_dir = self.config.get('logging', {}).get('log_dir', 'logs')
        log_file = self.config.get('logging', {}).get('chat_history_file', 'chat_history.txt')
        
        os.makedirs(log_dir, exist_ok=True)
        log_path = os.path.join(log_dir, log_file)
        
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(f"[{timestamp}] - Method: {log_type}\n")
            f.write(f"  USER: {query}\n")
            f.write(f"  BOT: {response}\n")
            f.write(f"{'-'*60}\n")